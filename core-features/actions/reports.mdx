---
title: "Understanding your performance"
description: "What reports include, cadence, and stakeholder-ready outputs"
---

## What reports include

Pierview reports summarize your AI visibility performance over a selected period. Typical sections:

- **Visibility** — How often your brand appeared across prompts and models
- **Sentiment** — Breakdown of positive, neutral, negative mentions
- **Citations** — Which sources were cited, including your domain
- **Competitor comparison** — Your share vs. competitors (when tracked)
- **Source breakdown** — Top cited domains and source gaps
- **Prompt-level detail** — Performance by individual prompt

## Reporting cadence

- **Weekly** — For active campaigns, quick iteration, content teams
- **Monthly** — For stakeholder reviews, trend tracking, exec summaries
- **Ad hoc** — After major content or PR pushes to measure impact

<Info>
  Run scans consistently (e.g., every Monday) so trend data is comparable.
</Info>

## Stakeholder-ready outputs

Reports can be tailored for different audiences:

| Output | Audience | Content |
|--------|----------|---------|
| **Exec summary** | Leadership | Visibility trend, key wins, top gaps, 3–5 action items |
| **Content backlog** | Content team | Source gaps → content ideas, citeable page opportunities |
| **PR targets** | PR team | Publications AI cites, angles for pitches |
| **Competitive brief** | Product/Marketing | Share of Answer, competitor source strategies |

## Sample report outline (text)

1. **Period** — e.g., Jan 1–31, 2025
2. **Summary** — Visibility up/down X%, citation rate at Y%
3. **Highlights** — Top 3 wins (e.g., new citations from G2, improved sentiment on key prompt)
4. **Gaps** — Source gaps to address, prompts with low visibility
5. **Recommendations** — 3–5 prioritized actions
6. **Appendix** — Prompt list, source table, raw metrics (optional)
